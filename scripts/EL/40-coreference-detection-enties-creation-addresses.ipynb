{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "229b50e8-b2c5-481a-aa09-acc71cd00abd",
   "metadata": {},
   "source": [
    "# 40 - Coreference detection and entities creation : example of the addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "645bda20-ac9c-4316-8fcf-94215a9811e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rdflib\n",
    "from rdflib import Graph, URIRef, Literal, RDFS, Namespace, BNode\n",
    "from rdflib.namespace import SKOS, RDF, RDFS, DCTERMS, XSD\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ecf6d3-e4ea-4d40-b263-28799603f351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Access to the utils directory\n",
    "current_dir = os.getcwd()\n",
    "utils_dir = os.path.join(current_dir, '..', 'utils')\n",
    "sys.path.append(utils_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "805990f9-b3c9-4414-89a2-8544ed57d0d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/STual/.venv/venv_sti/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /home/STual/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/STual/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from linking_utils import PrepareQueriesForEL\n",
    "from string_utils import NormalizeText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e9effc-4230-423e-99a0-ec55efe8d41c",
   "metadata": {},
   "source": [
    "### Retrieve the files and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aea585b-6605-4a33-88ab-9e22ccbd1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/home/STual/DAN-cadastre/\"\n",
    "FOLDER = \"LHAY\"\n",
    "DEP = \"94\"\n",
    "SAVE_FOLDER = f\"/home/STual/DAN-cadastre/data/{FOLDER}\"\n",
    "JSONS = glob.glob(f'{ROOT}inference/{FOLDER}/*.json') #WHere JSONS produced in DAN format output are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a84e5193-1365-43d2-ab31-4516af5316ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents : 26\n"
     ]
    }
   ],
   "source": [
    "plotaddresses = PrepareQueriesForEL.retrieve_mentions(JSONS, ROOT + 'inference/LHAY/', 'Ⓓ', False)\n",
    "print(f\"Number of documents : {len(plotaddresses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "585fc98f-7dfd-4139-984c-53dcc98d1af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct plotaddresses mentions : 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['la plaine', 'd', 'La plaine']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_plotaddresses = PrepareQueriesForEL.distinct_mentions_without_ne(plotaddresses)\n",
    "print(f\"Number of distinct plotaddresses mentions : {len(distinct_plotaddresses)}\")\n",
    "\n",
    "for i in range(len(distinct_plotaddresses)):\n",
    "    if distinct_plotaddresses[i] is None:\n",
    "        distinct_plotaddresses[i] = \"MISSING\"\n",
    "    else:\n",
    "        distinct_plotaddresses[i] = distinct_plotaddresses[i]\n",
    "distinct_plotaddresses[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0a1c5-90ed-4d81-b0e9-84361546da7d",
   "metadata": {},
   "source": [
    "## 1. Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "575f7c10-2e28-452a-bc9a-793872e50133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'address': 'la plaine'},\n",
       " {'address': 'd'},\n",
       " {'address': 'la plaine'},\n",
       " {'address': 'lavoie des'},\n",
       " {'address': 'de lhay'},\n",
       " {'address': 'foptaine'},\n",
       " {'address': 'lapplaine'},\n",
       " {'address': 'les'},\n",
       " {'address': 'ø'},\n",
       " {'address': 'laplaine'},\n",
       " {'address': 'la plane'},\n",
       " {'address': 'la voie des'},\n",
       " {'address': 'la voie'},\n",
       " {'address': 'des postey'},\n",
       " {'address': 'laptaine'},\n",
       " {'address': 'de 2thay'},\n",
       " {'address': 'laptain de '},\n",
       " {'address': 'la voie des'},\n",
       " {'address': 'missing'},\n",
       " {'address': 'de phay'},\n",
       " {'address': 'voie des'},\n",
       " {'address': 'voue des postes'},\n",
       " {'address': 'les sablons'},\n",
       " {'address': 'la plane'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotaddresses_mentions = []\n",
    "remove_chars_regex = '→()↑↓×±.,!?;:-@#$%^&*'\n",
    "replacement_char = ''\n",
    "\n",
    "for d in distinct_plotaddresses:\n",
    "    new_json = {}\n",
    "    if len(d) > 0:\n",
    "        new_json[\"address\"] = NormalizeText.remove_accents(NormalizeText.replace_characters(NormalizeText.replace_characters(d.lower(), '→', ' '),remove_chars_regex,replacement_char))\n",
    "    else:\n",
    "        new_json[\"address\"] = \"\"\n",
    "    if new_json[\"address\"] != \"missing\" or new_json[\"address\"] != \"ø\":\n",
    "        plotaddresses_mentions.append(new_json)\n",
    "plotaddresses_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682ba3ff-cfd8-4e39-afd4-2b9d0376872c",
   "metadata": {},
   "source": [
    "## 2. Create the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "163ddc07-da61-444f-b805-71e04416ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import Levenshtein as lev\n",
    "\n",
    "# Load the embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Helper function to compute normalized Levenshtein distance\n",
    "def normalized_levenshtein(str1, str2):\n",
    "    \"\"\"Returns a normalized Levenshtein distance (1 - distance)\"\"\"\n",
    "    \n",
    "    # Handle case where either string is empty\n",
    "    if len(str1) == 0 and len(str2) == 0:\n",
    "        return 1.0  # Both empty, consider them identical\n",
    "    \n",
    "    if len(str1) == 0 or len(str2) == 0:\n",
    "        return 0.0  # One is empty, completely dissimilar\n",
    "\n",
    "    # Normalized Levenshtein distance formula\n",
    "    return 1 - lev.distance(str1, str2) / max(len(str1), len(str2))\n",
    "\n",
    "# Helper function to cluster texts based on Levenshtein distance threshold\n",
    "def cluster_by_levenshtein(texts, threshold):\n",
    "    if len(texts) == 0:\n",
    "        return []\n",
    "\n",
    "    # Create a similarity matrix based on Levenshtein distance\n",
    "    sim_matrix = np.zeros((len(texts), len(texts)))\n",
    "\n",
    "    for i in range(len(texts)):\n",
    "        for j in range(i + 1, len(texts)):\n",
    "            sim = normalized_levenshtein(texts[i], texts[j])\n",
    "            sim_matrix[i][j] = sim_matrix[j][i] = sim\n",
    "\n",
    "    visited = set()\n",
    "    groups = []\n",
    "\n",
    "    for i in range(len(texts)):\n",
    "        if i in visited:\n",
    "            continue\n",
    "        group = [i]\n",
    "        visited.add(i)\n",
    "        for j in range(i + 1, len(texts)):\n",
    "            if j not in visited and sim_matrix[i][j] >= threshold:\n",
    "                group.append(j)\n",
    "                visited.add(j)\n",
    "        groups.append(group)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "# Helper function to cluster texts based on cosine similarity threshold\n",
    "def cluster_by_embeddings_similarity(texts, threshold):\n",
    "    if len(texts) == 0:\n",
    "        return []\n",
    "\n",
    "    embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "    sim_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "    visited = set()\n",
    "    groups = []\n",
    "\n",
    "    for i in range(len(texts)):\n",
    "        if i in visited:\n",
    "            continue\n",
    "        group = [i]\n",
    "        visited.add(i)\n",
    "        for j in range(i + 1, len(texts)):\n",
    "            if j not in visited and sim_matrix[i][j] >= threshold:\n",
    "                group.append(j)\n",
    "                visited.add(j)\n",
    "        groups.append(group)\n",
    "    return groups\n",
    "\n",
    "# Main function to group mentions\n",
    "def group_mentions_addresses(\n",
    "    mentions,\n",
    "    threshold=0.85,\n",
    "    mesure=\"normalizedlevenshtein\"\n",
    "):\n",
    "    \"\"\"\n",
    "    mentions: list of dicts, each with 'ADDRESS'\n",
    "    returns: list of list of indices, each list represents a group\n",
    "    \"\"\"\n",
    "    indices = list(range(len(mentions)))\n",
    "    values = [m['address'] for m in mentions]\n",
    "\n",
    "    # Step 1: Group by NAME similarity\n",
    "    if mesure == \"embeddingcosinus\":\n",
    "        final_groups = cluster_by_embeddings_similarity(values, threshold)\n",
    "    elif \"normalizedlevenshtein\":\n",
    "        final_groups = cluster_by_levenshtein(values, threshold)\n",
    "\n",
    "    return final_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef85995-12d8-41a7-9637-6310f78546c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = group_mentions_addresses(\n",
    "    plotaddresses_mentions,\n",
    "    threshold=0.80,\n",
    "    mesure=\"normalizedlevenshtein\"#embeddingcosinus normalizedlevenshtein\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bffc7f04-b9b1-4d6f-83ab-b9f032fdfb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "for li in groups:\n",
    "    for i in li:\n",
    "        counter += 1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2781d0a2-593d-4f40-9bd7-e0d30a439790",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert counter == len(distinct_plotaddresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd4ce3b1-063d-442e-9a06-5828f31624df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct groups : 15. Number of mentions : 24\n"
     ]
    }
   ],
   "source": [
    "from embedding_similarity import merge_lists_with_common_elements\n",
    "\n",
    "fusion_unique_groups = merge_lists_with_common_elements(groups)\n",
    "print(f\"Number of distinct groups : {len(fusion_unique_groups)}. Number of mentions : {len(distinct_plotaddresses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "245da629-ff45-4824-8d20-e1307375b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "la plaine\n",
      "La plaine\n",
      "lapplaine\n",
      "laplaine\n",
      "la plane\n",
      "La plane\n",
      "####################\n",
      "d\n",
      "####################\n",
      "Lavoie des\n",
      "La voie des\n",
      "La Voie des\n",
      "Voie des\n",
      "####################\n",
      "de Lhay\n",
      "de Phay\n",
      "####################\n",
      "foptaine\n",
      "####################\n",
      "Les\n",
      "####################\n",
      "Ø\n",
      "####################\n",
      "La Voie\n",
      "####################\n",
      "des postey\n",
      "####################\n",
      "laptaine\n",
      "####################\n",
      "de 2thay\n",
      "####################\n",
      "Laptain de→\n",
      "####################\n",
      "MISSING\n",
      "####################\n",
      "Voue des→Postes\n",
      "####################\n",
      "Les sablons\n"
     ]
    }
   ],
   "source": [
    "DISPLAY_GROUPS = True\n",
    "if DISPLAY_GROUPS : \n",
    "    for l in fusion_unique_groups:\n",
    "        print(\"####################\")\n",
    "        for i in l:\n",
    "            print(distinct_plotaddresses[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea87f80f-f70e-4a56-9b8b-a5f9f8349513",
   "metadata": {},
   "source": [
    "## 3. Create RDF Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d190cf8a-f8be-468a-9b88-30de08fff484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein as lev\n",
    "from collections import Counter\n",
    "import uuid\n",
    "\n",
    "# Helper function to calculate the representative name (minimal Levenshtein distance)\n",
    "def get_representative_name(names):\n",
    "    min_distance = float('inf')\n",
    "    representative_name = None\n",
    "    \n",
    "    for name in names:\n",
    "        avg_distance = sum(normalized_levenshtein(name, other_name) for other_name in names) / len(names)\n",
    "        if avg_distance < min_distance:\n",
    "            min_distance = avg_distance\n",
    "            representative_name = name\n",
    "    \n",
    "    return representative_name\n",
    "\n",
    "# Helper function to calculate the longest string\n",
    "def get_longest_string(strings):\n",
    "    return max(strings, key=len)\n",
    "\n",
    "# Helper function to calculate the most appropriate family status\n",
    "def get_representative_familystatus(familystatuses):\n",
    "    # Filter out \"id\" and \"idem\" if they are not the only values\n",
    "    filtered_statuses = [status for status in familystatuses if status.lower() not in [\"id\", \"idem\"]]\n",
    "    \n",
    "    if filtered_statuses:\n",
    "        return get_longest_string(filtered_statuses)  # Choose the longest one among filtered values\n",
    "    else:\n",
    "        return get_longest_string(familystatuses)  # If \"id\" or \"idem\" are the only options, choose the longest one\n",
    "\n",
    "# Function to create RDF entities based on the most representative values\n",
    "def create_rdf_entities(groups, mentions):\n",
    "    rdf_entities = []\n",
    "\n",
    "    for group in groups:\n",
    "        group_mentions = [mentions[i] for i in group]\n",
    "        \n",
    "        # Step 1: Choose the representative name\n",
    "        names = [m['address'] for m in group_mentions]\n",
    "        representative_name = get_representative_name(names)\n",
    "\n",
    "        # Create RDF entity for this group\n",
    "        rdf_entity = {\n",
    "            'uuid': str(uuid.uuid4()),\n",
    "            'address': representative_name.title(),\n",
    "            'mentions': group  # Link this entity to the list of mentions in the group\n",
    "        }\n",
    "\n",
    "        rdf_entities.append(rdf_entity)\n",
    "    \n",
    "    return rdf_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a514cd6-5c1a-450e-a017-9faa1acab53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_entities = create_rdf_entities(fusion_unique_groups, plotaddresses_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46e7de4a-e507-4777-9e6b-a57d55b5f075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdf_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d255ce63-2bb1-4ddb-b3f1-fc73be0b30f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uuid': '8faa03de-adbd-44e0-b936-eed5f0a916c9',\n",
       " 'address': 'Voie Des',\n",
       " 'mentions': [3, 11, 17, 20]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf_entities[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "193d39ec-f7b3-40b2-98b3-ecd42fa309cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rdf_resource(rdf_entities, distinct_mentions):\n",
    "    \"\"\"\n",
    "    Create a simple RDF resource for each group with additional properties (address, activity, title).\n",
    "    \"\"\"\n",
    "    g = Graph()\n",
    "    ADDR = Namespace(\"http://rdf.geohistoricaldata.org/def/address#\")\n",
    "    CAD = Namespace(\"http://rdf.geohistoricaldata.org/def/cadastre#\")\n",
    "    LTYPE = Namespace(\"http://rdf.geohistoricaldata.org/id/codes/address/landmarkType/\")\n",
    "    LANDMARK = Namespace(\"http://rdf.geohistoricaldata.org/id/landmark/\")\n",
    "    CAD_LTYPE = Namespace(\"http://rdf.geohistoricaldata.org/id/codes/cadastre/landmarkType/\")\n",
    "    LRTYPE = Namespace(\"http://rdf.geohistoricaldata.org/id/codes/address/landmarkRelationType/\")\n",
    "    LR = Namespace(\"http://rdf.geohistoricaldata.org/id/landmarkRelation/\")\n",
    "    g.bind(\"addr\", ADDR)\n",
    "    g.bind(\"cad\", CAD)\n",
    "    g.bind(\"landmark\", LANDMARK)\n",
    "    g.bind(\"cad_ltype\", CAD_LTYPE)\n",
    "    g.bind(\"lrtype\", LRTYPE)\n",
    "    g.bind(\"landmarkRelation\", LR)\n",
    "    uris_dict = {}\n",
    "    \n",
    "    for rdf_entity in rdf_entities:\n",
    "        if rdf_entity['address'] != 'Ø':\n",
    "            uri = URIRef(LANDMARK + rdf_entity['uuid'])\n",
    "            g.add((uri, RDF.type, ADDR.Landmark))\n",
    "            g.add((uri, ADDR.isLandmarkType, LTYPE.Undefined))\n",
    "\n",
    "            #uri_lr = URIRef(BNode().n3())\n",
    "            p1 = uri.replace(\"http://rdf.geohistoricaldata.org/id/landmark/\",uri)\n",
    "            uri_lr = URIRef(LR+p1 + '_' + DEP + '_' + FOLDER)\n",
    "            g.add((uri_lr, RDF.type, ADDR.LandmarkRelation))\n",
    "            g.add((uri_lr, ADDR.isLandmarkRelationType, LRTYPE.Within))\n",
    "            g.add((uri_lr, ADDR.locatum, uri))\n",
    "            g.add((uri_lr, ADDR.relatum, URIRef(LANDMARK + DEP + '_' + FOLDER)))\n",
    "    \n",
    "            mentions = rdf_entity[\"mentions\"]\n",
    "            for m in mentions:\n",
    "                key = distinct_mentions[m]\n",
    "                uris_dict[key] = str(uri)\n",
    "        \n",
    "            # Address name\n",
    "            if len(rdf_entity['address']) > 0:\n",
    "                label = rdf_entity['address']\n",
    "            \n",
    "            label = re.sub('→',' ',label)\n",
    "            label = re.sub('↑',' ',label)\n",
    "            label = re.sub('↓',' ',label)\n",
    "            label = re.sub('  ',' ',label)\n",
    "            label = re.sub('[ ]+$','',label)\n",
    "            g.add((uri, RDFS.label, Literal(label)))\n",
    "\n",
    "    return g, uris_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4734750d-a07a-457c-9ecb-5f123d1d2771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nb1426a20fa1740b0a1153ea3f35eac3b (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate RDF resource\n",
    "graph, uris_dict = generate_rdf_resource(rdf_entities, distinct_plotaddresses)\n",
    "\n",
    "# Print the RDF graph in Turtle format\n",
    "graph.serialize(destination=f\"{SAVE_FOLDER}/rdf/lieu-dit.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a7c755-aa96-4306-8d21-4737a943c397",
   "metadata": {},
   "source": [
    "## 4. Annotate the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65713bf7-cf9b-4023-9ad6-ca3adf6c4cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for JSON in JSONS:\n",
    "    with open(JSON) as f:\n",
    "        page = json.load(f)\n",
    "    page_uuid = JSON.replace(ROOT + \"inference/LHAY\",\"\").replace('.json','')\n",
    "\n",
    "    for line in page[\"entities\"]:\n",
    "        if \"Ⓓ\" in list(line.keys()):\n",
    "            if line[\"Ⓓ\"][\"interpreted_text\"] != None:\n",
    "                if line[\"Ⓓ\"][\"interpreted_text\"] != 'Ø':\n",
    "                    line[\"Ⓓ\"]['uris'] = uris_dict[line[\"Ⓓ\"][\"interpreted_text\"]]\n",
    "\n",
    "    with open(JSON,'w', encoding='utf-8') as f:\n",
    "        json.dump(page, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
